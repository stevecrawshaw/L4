<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Steve Crawshaw">

<title>Final project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="Final project_files/libs/clipboard/clipboard.min.js"></script>
<script src="Final project_files/libs/quarto-html/quarto.js"></script>
<script src="Final project_files/libs/quarto-html/popper.min.js"></script>
<script src="Final project_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Final project_files/libs/quarto-html/anchor.min.js"></script>
<link href="Final project_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Final project_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Final project_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Final project_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Final project_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Final project</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Steve Crawshaw </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="project-to-develop-a-process-for-monthly-diagnostics-and-qa-reporting-from-air-monitors-and-telemetry-devices" class="level1">
<h1>Project: To develop a process for monthly diagnostics and QA reporting from air monitors and telemetry devices</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The QA (Quality Assurance) process for air quality measurements is set out in the relevant guidance <a href="https://laqm.defra.gov.uk/wp-content/uploads/2022/08/LAQM-TG22-August-22-v1.0.pdf">LAQM.TG(22)</a>. The guidance is from the government department Defra, who are the customer, or client for this activity.</p>
<p>Bristol City Council follows this guidance which essentially requires regular calibration of NOx analysers with a traceable gas. In addition to the calibration activity, other datasets are helpful in verifying and maintaining the good operation of the monitoring network.</p>
<p>The aim of this project is to bring all those sources of data together in a coherent report to summarise the operating characteristics of the monitoring system and provide assurance that the system is operating within desired parameters. The risk to data quality is thereby minimised because data problems are identified early and mitigating measures can be implemented, such as replacing calibration gas, service engineer visits etc.</p>
</section>
<section id="data-sources" class="level2">
<h2 class="anchored" data-anchor-id="data-sources">Data Sources</h2>
<p>The sources of data are summarised as follows:</p>
<ol type="1">
<li>SQL server database (Envista). Stores air quality measurements and diagnostics data</li>
<li>Google Drive. Calibration data is collected in the field with google forms and stored in google sheets</li>
<li>Teltonika Remote Management System (RMS). Parameters for the 4G routers which provide telemetry to the network are available through a REST API.</li>
</ol>
</section>
<section id="data-characteristics" class="level2">
<h2 class="anchored" data-anchor-id="data-characteristics">Data Characteristics</h2>
<p>The data used are not classified as personal data. They relate to the operation of the monitoring network and are only of interest to the team managing the operation of the network, or a third party auditor of air quality data such as the UK government or their consultants. The data are not published but could be made available on request. The data are structured, tabular or converted to such from an REST API source.</p>
</section>
<section id="data-processing-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="data-processing-pipeline">Data Processing Pipeline</h2>
<p>The pipeline for this project was built in R, using the <code>targets</code> package to ensure reproducibility and organise the functions. Data are extracted from the data sources, using database connections, the <code>googlesheets4</code> R package and the RMS API provided by Teltonika. Various data cleaning and processing functions are implemented in the targets pipeline to prepare the data for output in a Quarto document.</p>
</section>
<section id="data-processing-examples" class="level2">
<h2 class="anchored" data-anchor-id="data-processing-examples">Data Processing Examples</h2>
<section id="derive-summary-statistics-for-missing-data" class="level3">
<h3 class="anchored" data-anchor-id="derive-summary-statistics-for-missing-data">Derive Summary Statistics for Missing Data</h3>
<p>A key requirement within the air quality guidance LAQM.TG(22) is that data capture should be maximised and should match or exceed 85% for hourly continuous measurements. Hence a valuable monthly check is the amount of missing data in that month. If significant data are missing it usually indicates a machine or telemetry fault.</p>
<p>In order to calculate this, the hourly continuous data for each instrument is retrieved from the envista database and a function is iterated over the complete dataset to derive the number and percentage of missing observations. The function to retrieve data from envista is not shown as it is quite lengthy, but the missing data calculation is shown below.</p>
<p>The consolidated long aq_data_tbl is split into a list of tibbles, completely empty (redundant) columns removed, and the <code>miss_var_summary()</code> function from the <code>naniar</code> package is mapped over each tibble in the list. The relevant pollutants are filtered from the resulting tibble and the columns are selected and renamed with <code>transmute()</code> function. The resulting tibble is piped into a <code>gt()</code> table in the targets pipeline.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-calc-missing.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Missing data calculation function</figcaption><p></p>
</figure>
</div>
</section>
<section id="extract-and-process-diagnostics-data" class="level3">
<h3 class="anchored" data-anchor-id="extract-and-process-diagnostics-data">Extract and Process Diagnostics Data</h3>
<p>Diagnostics data from the Teledyne API chemiliminescent NOx analysers are captured in a SQL server database on an on - site EnviDAS FW data logger. The data loggers are polled hourly and both measurement and diagnostics data are stored in a corporate SQL server database called “envista”. The diagnostics data are extracted for the reporting.</p>
<p>The code below sets up a database connection by retrieving the connection parameters from a config.yml file. This ensures the credentials are safely stored and not embedded in the code. Even if web based version control (i.e.&nbsp;GitHub) is used, the config.yml file can be added to .gitignore to ensure that the credentials are not published.</p>
<p>The connection object is then used to retrieve the diagnostics table in the get.diag.tbl() function. This function also takes two date parameters and filters the diagnostics table so that only the temporal subset of data needed is retrieved. This function uses the <code>dbplyr</code> backend to generate SQL in R.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-diag-retrieve.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Extract and process diagnostics table from database</figcaption><p></p>
</figure>
</div>
<p>An example of further data processing on the diagnostics data is shown below. This function takes a long version of the diagnostics table, a data frame holding upper and lower limits for the diagnostics parameters, and a data frame relating the site ID’s in the diagnostics table to meaningful site names. It filters for missing, data cleans column data by trimming white space and joins the three data sets to return a cleaned diagnostics table in long format used later in plotting and tabulation. The upper and lower limit data are used in the plotting function to show the normal operating characteristics of the instrument. The line plot for each parameter should normally be within the limits.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-join-filter-mutate-diag-table.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Cleaning and joining diagnostics data</figcaption><p></p>
</figure>
</div>
<section id="extract-and-process-calibration-data" class="level4">
<h4 class="anchored" data-anchor-id="extract-and-process-calibration-data">Extract and Process Calibration Data</h4>
<p>Fortnightly visits to site capture zero and span calibration measurements for the NOx instruments using a zero air scrubber and a traceable span gas with a known concentration of nitric oxide. The data are entered on a mobile phone or tablet using Google forms and are held on a Google spreadsheet. The spreadsheet calculates the zero and span factors from the data entered, as well as meta data such as the gas bottle ID to ensure traceability in the calibration process. The screenshot below shows a portion of the calibration form used on a mobile device.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-center">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/googleform_cals.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Calibration data capture form</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/googleform_cals_2.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Calibration data capture form</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
<p>The <code>googlesheets4</code> package in the <code>tidyverse</code> metapackage in R is used to access the google spreadsheet using the google credentials object, which again is stored in the config.yml file for security. The two functions shown below retrieve calibration and gas metadata from the spreadsheet and range specified in the <code>read_sheet()</code> functions and perform minimal data cleaning before returning a data frame.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-get-cal-gas-tbl.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Retrieve calibration and gas data</figcaption><p></p>
</figure>
</div>
</section>
<section id="create-output-table-for-calibration-factors-and-targets" class="level4">
<h4 class="anchored" data-anchor-id="create-output-table-for-calibration-factors-and-targets">Create Output Table for Calibration Factors and Targets</h4>
<p>The <code>gt</code> package in R was used to create a high quality table showing how calibrations compared against ideal values. The calibration data retrieved is pre - processed and passed to the function below. This function filters the data, sets targets for the calibration factors - zero for zero calibration and one for span calibration and groups the resulting data frame by site and date. This data frame is then piped into the <code>gt()</code> function which creates the output table as html. Various formatting functions are used to create the table in an attractive format which conveys the necessary information quickly and clearly to the reader.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-cal-factors-gt.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Calibration factors table</figcaption><p></p>
</figure>
</div>
</section>
<section id="retrieving-airtime-data-from-routers" class="level4">
<h4 class="anchored" data-anchor-id="retrieving-airtime-data-from-routers">Retrieving Airtime Data from Routers</h4>
<p>The Teltonika RMS REST API is used to retrieve router meta - data including airtime data use. Airtime data is limited to 3GB per device spread over all SIMS provided by our airtime provider. Exceeding this limit results in excess charges or potentially loss of telemetry. The screenshot below shows the device overview for the routers used in the air quality telemetry.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/rms_screen.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">RMS screenshot</figcaption><p></p>
</figure>
</div>
<p>The function shown below takes the date span of interest, the device_url endpoint, the API Personal Access Token (PAT) - which is stored in an offline config.yml file, and a data frame holding the device ID’s. the <code>single.site.data()</code> function within it gets data for a single device. This function is then partialised and mapped over the ID’s of the routers to return a data frame with the daily data use for each device in a single table. This is subsequently used in a plot function.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-data-use-routers.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Retrieve airtime data from routers</figcaption><p></p>
</figure>
</div>
</section>
<section id="plot-daily-data-use-of-routers" class="level4">
<h4 class="anchored" data-anchor-id="plot-daily-data-use-of-routers">Plot Daily Data use of Routers</h4>
<p>The function shown below takes a data frame of the daily data receive and transmit totals and uses the <code>ggplot</code> package to plot a faceted column chart showing daily receive and transmit data totals for each router. Appropriate theme adjustments are made to make a visually appealing chart.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-daily-data-plot-routers.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Daily data use</figcaption><p></p>
</figure>
</div>
</section>
<section id="targets-pipeline" class="level4">
<h4 class="anchored" data-anchor-id="targets-pipeline">Targets Pipeline</h4>
<p>All the functions used in the pipeline are implemented through the <code>targets</code> package. This creates a reproducible workflow by learning the dependencies in the pipeline and skipping redundant targets. This can save time when designing and testing the pipeline as computationally expensive targets are not re - run unnecessarily. Objects (targets) created by the targets pipeline are hashed to track changes to the data file. The hashes determine whether the target needs to be re - run.</p>
<p>The targets pipeline is built by coding a list of targets, where each target’s name is the object resulting from the command (function) of that target. A truncated example of the target’s list in this project is shown below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-targets-extract.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Truncated targets pipeline list</figcaption><p></p>
</figure>
</div>
<p>The dependencies created by the targets pipeline can be viewed using the <code>tar_visnetwork()</code> function. The image below is a subset of the entire network graph for the targets pipeline in this project and shows how functions, targets and outputs are related. The dependencies for the <code>data_summary_tbl</code> object are highlighted.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tar-visnetwork.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Extract of targets pipeline visual network graph</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="reporting" class="level3">
<h3 class="anchored" data-anchor-id="reporting">Reporting</h3>
<p>The final reporting product needs to be easily readable and to highlight the key parameters which govern measurement quality and system reliability. I decided that an html output from a Quarto document would be the ideal option. The file is portable across systems and can be easily published for sharing with e.g.&nbsp;service contractors on a website such as Quarto pubs.</p>
<p>The key outputs in the report are as follows.</p>
<ol type="1">
<li>A <code>gt</code> table showing the amount and percentage of missing data for the measurement period</li>
<li>A <code>gt</code> table with sparklines showing the calibration factors used and their ideal target values. This is broken down by pollutant and site and indicates whether calibrations are providing correct data which which to adjust the measurement data.</li>
<li>A chart showing the divergence of span values for two pollutants. This can indicate problems with contamination in calibration gas cylinders.</li>
<li>Charts showing the data use of airtime data allowances by routers. This can help identify excessive data use, which could indicate security breach or operating system problem. If data thresholds are exceeded, airtime can be cut which would inhibit our real time reporting of air quality measurements.</li>
<li>Time series charts of instrument diagnostics. These are compared to high and low “normal operating characteristics” to show when instrument problems may be developing. This could for example be the sample pressure declining, indicating a leak in the system.</li>
</ol>
<section id="generating-the-qa-report" class="level4">
<h4 class="anchored" data-anchor-id="generating-the-qa-report">Generating the QA Report</h4>
<p>The report components listed above are generated by the targets pipeline and compiled into a Quarto document rendered into HTML. This process works by referencing the objects created in the targets pipeline within R code chunks in the qa_report.qmd Quarto document. An extract from the QA report is reproduced below to illustrate the format.</p>
<p>The top three lines are YAML which sets up the title, author and format. The next chunk, denoted by backticks (```) sets options and packages. The following sections are combined text and code chunks, similar to an iPython notebook. The R code in the chunks reads the relevant target to source and render the visualisation using the <code>tar_read()</code> function.</p>
<p>The overall process for running the pipeline and rendering the report is in three steps.</p>
<ol type="1">
<li>Enter the start and end dates in the functions.R file</li>
<li>Run _targets.R using the <code>tar_make()</code> command</li>
<li>Render the qa_report.qmd report to create and display the HTML report</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/r-code-quarto-qa-report.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Extract of Quarto QA report</figcaption><p></p>
</figure>
</div>
<p>Although the final reporting will be through an html rendered quarto document, some examples are shown below.</p>
<p>This chart shows the diagnostics data for a single site. Some familiarity with the principle of operation of the instruments is needed to parse the data shown. The officer reading the report can be guided by the upper and lower limits shown in dotted blue lines. The chart or document can easily be sent to the equipment support unit (ESU - a third party company that maintains the instruments) to help them diagnose problems with the instrument.</p>
<p>Essentially the instruments contain components that should be maintained within certain parameters, for example Internal Box Temperature (the temperature inside the instrument should not go above 40C). If maximum temperature exceeds this level a malfunction could arise. Similarly a sample flow rate that deviates from the upper and lowe limits could indicate a leak or pump failure.</p>
<!-- :::{layout-ncol=2 layout-valign="center"} -->
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="project-2-diagnostics/qa_report_files/figure-html/diag_plot_1-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Diagnostics plot: Brislington</figcaption><p></p>
</figure>
</div>
<p>The bar chart shown below indicates the daily receive and transmit data use for each router. The Teltonika routers use multi - network SIMs that are capped at 3GB per month. Allowances are shared over all SIMs and refresh on the first day of each month. Six sites operated by BCC have EnviDAS data loggers running Windows 10. Windows updates and other downloads related to the loggers consume the majority of the data. Updates are often run at the end of the month so high data use is normal to see here.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="project-2-diagnostics/qa_report_files/figure-html/data_use_1-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Daily 4G data use</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="project-2-diagnostics/qa_report_files/figure-html/cumulative_data_use-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Cumulative data use for period</figcaption><p></p>
</figure>
</div>
<p>The calibration factors chart shown below gives a visual check for the zero and span calibration factors for each pollutant at each calibration.</p>
<p>Zero calibration factors should be close to zero. When levels approach 2 or greater, this could indicate a leak in the sample line to the bottle or another problem.</p>
<p>Sensitivity calibration factors should be close to 1. Factors greater than 1.5 could indicate contamination of the gas bottle.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cal_factors.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Calibration factors</figcaption><p></p>
</figure>
</div>
<p>Span readings should be similar for NOx and NO. The stated value for NOx and NO on the trace gas is usually within 1 - 2 ppb of each other. High variance in span calibration readings can indicate a contaminated cylinder. If no line is plotted it is likely that only one calibration was done in the period selected.</p>
<p>In the example shown below, the Parson Street site is showing a significant change in the divergence between NOx and NO span values. This should trigger a call out to the ESU, who would advise on remedial action, in this case that the cause is likely to be a contaminated gas cylinder, where air has entered the cylinder and changed the concentration of the gas through oxidation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="project-2-diagnostics/qa_report_files/figure-html/span_divergence-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Span divergence</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="business-benefits" class="level3">
<h3 class="anchored" data-anchor-id="business-benefits">Business Benefits</h3>
<p>It is vital that stakeholders have confidence in the quality of air quality data. Multi - million pound decisions are taken on the evidence from air quality monitoring such as the implementation of a Clean Air Zone (CAZ). Hence there is a great deal of scrutiny of the data which must be defendable. The output from this project demonstrates that a rigorous QA process is conducted at monthly intervals on the data. It also ensures that operational parameters are regularly reviewed to maintain reliable data flow and real time publishing of our air quality data.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>